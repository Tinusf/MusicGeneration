from collections import defaultdict
from typing import Tuple
from collections import Counter
import numpy as np
from music21 import *
import os
import pickle
import config


def load_all_midi_files() -> np.ndarray:
    pickle_path = "midi_files_array.pickle"
    if (config.LOAD_CACHED_MIDI_FILES and os.path.exists(pickle_path)):
        return pickle.load(open(pickle_path, "br"))

    # Data downloaded from https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/
    path = config.MIDI_DIRECTORY
    files = [i for i in os.listdir(path) if i.endswith(".mid")]
    array = np.array([read_midi(path + i) for i in files])
    pickle.dump(array, open(pickle_path, "bw"))
    return array


def get_duration_from_index(index):
    return [1, 0.8, 0.5, 0.3, 0.15, 0.0][index]


def get_duration_bucket_index(duration):
    # In order to not get that many different durations, have a couple of buckets instead.
    duration_buckets = [1, 0.8, 0.5, 0.3, 0.15, 0.0]
    for i, bucket in enumerate(duration_buckets):
        if duration >= bucket:
            return i


# defining function to read MIDI files
def read_midi(file: str) -> np.ndarray:
    print("Loading Music File:", file)

    notes = []
    notes_to_parse = None

    # parsing a midi file
    midi = converter.parse(file)

    # grouping based on different instruments
    s2 = instrument.partitionByInstrument(midi)

    # a dictionary with key offset and value which note and instrument str. "pianoE3"
    # after this merge things into like: "pianoE3ViolinE1"
    notes = defaultdict(lambda: "")

    for part in s2.parts:
        # select elements of only piano
        if 'Piano' in str(part):
            notes_to_parse = part.recurse()
            # finding whether a particular element is note or a chord
            for element in notes_to_parse:
                totalOffset = element.getOffsetInHierarchy(midi)
                # note
                if isinstance(element, note.Note):
                    try:
                        seconds_bucket = get_duration_bucket_index(element.seconds)
                    except:
                        seconds_bucket = get_duration_bucket_index(0.5)
                    notes[totalOffset] += "piano" + str(element.pitch) + "bucket:" + str(seconds_bucket)
                # chord
                elif isinstance(element, chord.Chord):
                    notes[totalOffset] += "piano" + '.'.join(str(n) for n in element.normalOrder)
        elif "Violin" in str(part):
            notes_to_parse = part.recurse()
            # finding whether a particular element is note or a chord
            for element in notes_to_parse:
                totalOffset = element.getOffsetInHierarchy(midi)
                # note
                if isinstance(element, note.Note):
                    seconds_bucket = get_duration_bucket_index(element.seconds)
                    notes[totalOffset] += "violin" + str(element.pitch) + "bucket:" + str(seconds_bucket)
                # chord
                elif isinstance(element, chord.Chord):
                    notes[totalOffset] += "violin" + '.'.join(str(n) for n in element.normalOrder)

    output_notes = []
    for offset in sorted(notes):
        _note = notes[offset]
        output_notes.append(_note)

    return np.array(output_notes)


def get_frequency_dict(notes: np.ndarray) -> dict:
    # Flatten the notes array.
    notes_1d = [element for note_ in notes for element in note_]
    # Frequency dictionary.
    return dict(Counter(notes_1d))


def get_frequent_notes(notes: np.ndarray) -> list:
    freq = get_frequency_dict(notes)
    # Return the notes that have a count of 50 or above.
    return [note_ for note_, count in freq.items() if count >= 50]


def filter_frequent_notes(notes: np.ndarray, frequent_notes: list) -> np.ndarray:
    return np.array([[_note for _note in one_song if _note in frequent_notes] for one_song in notes])


def create_training_dataset(notes: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    This method creates a dataset containing 32 notes as input and a single note as output for those 32 notes.
    :param notes: Numpy array of notes.
    :return: X, y dataset.
    """
    no_of_timesteps = 32
    x = []
    y = []

    for _note in notes:
        for i in range(0, len(_note) - no_of_timesteps, 1):
            input_notes = _note[i:i + no_of_timesteps]
            output_note = _note[i + no_of_timesteps]

            x.append(input_notes)
            y.append(output_note)

    return np.array(x), np.array(y)


def convert_to_midi(prediction_output):
    offset = 0
    # dictionary with key being instrument and value being the notes.
    output_notes = stream.Part()
    output_notes.insert(0, tempo.MetronomeMark(number=120))
    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        while pattern != "":
            cur_instrument = None
            if pattern.startswith("violin"):
                pattern = pattern.replace("violin", "", 1)
                cur_instrument = instrument.Violin()
            elif pattern.startswith("piano"):
                pattern = pattern.replace("piano", "", 1)
                cur_instrument = instrument.Piano()

            closest_i = 1000
            piano_i = pattern.find("piano")
            violin_i = pattern.find("violin")
            if piano_i > -1:
                closest_i = min(closest_i, piano_i)
            if violin_i > -1:
                closest_i = min(closest_i, violin_i)
            current_notes = pattern[0:closest_i]
            pattern = pattern.replace(current_notes, "", 1)

            index = current_notes.find("bucket:")
            seconds = 0.5
            if index > -1:
                bucket_i = current_notes[index + 7]
                current_notes = current_notes.replace("bucket:" + bucket_i, "", 1)
                seconds = get_duration_from_index(int(bucket_i))

            # pattern is a chord
            if ('.' in current_notes) or current_notes.isdigit():
                notes_in_chord = current_notes.split('.')
                notes = []
                for current_note in notes_in_chord:
                    cn = int(current_note)
                    new_note = note.Note(cn)
                    new_note.offset = offset
                    new_note.storedInstrument = cur_instrument
                    # mm1 = tempo.MetronomeMark(number=120)
                    # lol = type(mm1)
                    # # new_note.sites = mm1
                    # # new_note.duration = mm1
                    # new_note.tempo = mm1

                    # try:
                    # _sites = sites.Sites()
                    # _sites.add(mm1)
                    # new_note.sites.add(mm1)
                    #     print("works")
                    # except:
                    #     pass
                    output_notes.append(new_note)
                    new_note.seconds = seconds

                new_chord = chord.Chord(notes)
                new_chord.offset = offset
                try:
                    new_chord.seconds = seconds
                    print("works")
                except:
                    pass
                output_notes.append(cur_instrument)
                output_notes.append(new_chord)

            # pattern is a note
            else:
                new_note = note.Note(current_notes)
                new_note.offset = offset
                new_note.storedInstrument = cur_instrument
                try:
                    new_note.seconds = seconds
                    print("works")
                except:
                    pass
                output_notes.append(cur_instrument)
                output_notes.append(new_note)
        offset += 1

    p1 = stream.Part()
    p1.insert(output_notes)
    song = stream.Stream()
    song.append(p1)
    song.write('midi', fp='music.mid')
